#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç”Ÿæˆ V4 Colab è®­ç»ƒ Notebookï¼ˆSOTA ä¼˜åŒ–ç‰ˆï¼‰
"""

import json
from pathlib import Path


def generate_v4_notebook():
    """ç”Ÿæˆ V4 è®­ç»ƒ notebook"""
    
    notebook = {
        "nbformat": 4,
        "nbformat_minor": 0,
        "metadata": {
            "colab": {
                "provenance": [],
                "gpuType": "T4"
            },
            "kernelspec": {
                "name": "python3",
                "display_name": "Python 3"
            },
            "language_info": {
                "name": "python"
            },
            "accelerator": "GPU"
        },
        "cells": []
    }

    # Cell 1: æ ‡é¢˜å’Œè¯´æ˜
    notebook["cells"].append({
        "cell_type": "markdown",
        "metadata": {"id": "title"},
        "source": [
            "# æ¢§æ¡æ¯ AI å®‰å…¨å‘Šè­¦æ™ºèƒ½ç ”åˆ¤ç³»ç»Ÿ - V4 SOTA ä¼˜åŒ–ç‰ˆï¼ˆå†²å‡» 99.5%+ï¼‰\n",
            "\n",
            "## ğŸ¯ V4 æ ¸å¿ƒä¼˜åŒ–\n",
            "\n",
            "1. â­â­â­â­â­ **SMOTE è¿‡é‡‡æ ·**ï¼šè§£å†³ç±»åˆ«ä¸å¹³è¡¡ï¼Œé¢„æœŸ +0.8-1.2%\n",
            "2. â­â­â­â­ **XGBoost æ·±åº¦ä¼˜åŒ–**ï¼š500 æ ‘ + æ·±åº¦ 12ï¼Œé¢„æœŸ +0.3-0.5%\n",
            "3. â­â­â­ **é›†æˆæƒé‡ä¼˜åŒ–**ï¼šä¼˜åŒ– meta-learnerï¼Œé¢„æœŸ +0.1-0.2%\n",
            "4. âœ¨ **10 æŠ˜äº¤å‰éªŒè¯**ï¼šæ›´ç¨³å®šçš„æ€§èƒ½è¯„ä¼°\n",
            "\n",
            "## ğŸ“‹ è®­ç»ƒæµç¨‹\n",
            "\n",
            "1. âœ… å…‹éš† GitHub ä»“åº“\n",
            "2. âœ… å®‰è£…ä¾èµ–ï¼ˆå« imbalanced-learnï¼‰\n",
            "3. âœ… æ£€æŸ¥ GPU\n",
            "4. âœ… æ£€æŸ¥æ•°æ®\n",
            "5. âœ… æ•°æ®é¢„å¤„ç†\n",
            "6. âœ… æ•°æ®å¢å¼º\n",
            "7. âœ… **è®­ç»ƒ V4 æ¨¡å‹ï¼ˆSMOTE + ä¼˜åŒ–è¶…å‚æ•°ï¼‰**\n",
            "8. âœ… æŸ¥çœ‹ç»“æœ\n",
            "9. âœ… ä¸‹è½½æ¨¡å‹\n",
            "\n",
            "## ğŸ¯ ç›®æ ‡\n",
            "\n",
            "- **å‡†ç¡®ç‡ç›®æ ‡**: 99.5%+\n",
            "- **V3 åŸºçº¿**: 98.36%\n",
            "- **é¢„æœŸæå‡**: +1.1-1.6%\n",
            "- **è®­ç»ƒæ—¶é—´**: çº¦ 30-40 åˆ†é’Ÿ\n",
            "- **æ¨¡å‹ç‰ˆæœ¬**: v4.0.0\n",
            "\n",
            "## âš™ï¸ è¿è¡Œå‰å‡†å¤‡\n",
            "\n",
            "1. ç¡®ä¿è¿è¡Œæ—¶ç±»å‹è®¾ç½®ä¸º **GPU**ï¼ˆRuntime > Change runtime type > GPUï¼‰\n",
            "2. æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªå•å…ƒæ ¼\n",
            "\n",
            "---"
        ]
    })

    # Cell 2: å…‹éš†ä»“åº“
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {"id": "clone"},
        "source": [
            "# 1. å…‹éš† GitHub ä»“åº“\n",
            "!git clone https://github.com/alltobebetter/WuTong.git\n",
            "%cd WuTong\n",
            "\n",
            "# æŸ¥çœ‹é¡¹ç›®ç»“æ„\n",
            "!ls -la"
        ],
        "execution_count": None,
        "outputs": []
    })

    # Cell 3: å®‰è£…ä¾èµ–
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {"id": "install"},
        "source": [
            "# 2. å®‰è£…ä¾èµ–ï¼ˆå« imbalanced-learnï¼‰\n",
            "print(\"ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...\")\n",
            "!pip install -q -r requirements.txt\n",
            "\n",
            "print(\"\\nâœ… ä¾èµ–å®‰è£…å®Œæˆï¼\")\n",
            "\n",
            "# éªŒè¯å…³é”®åŒ…\n",
            "import xgboost as xgb\n",
            "import catboost as cb\n",
            "import lightgbm as lgb\n",
            "import pandas as pd\n",
            "from imblearn.over_sampling import SMOTE\n",
            "\n",
            "print(f\"XGBoost ç‰ˆæœ¬: {xgb.__version__}\")\n",
            "print(f\"CatBoost ç‰ˆæœ¬: {cb.__version__}\")\n",
            "print(f\"LightGBM ç‰ˆæœ¬: {lgb.__version__}\")\n",
            "print(f\"Pandas ç‰ˆæœ¬: {pd.__version__}\")\n",
            "print(f\"âœ… SMOTE å·²å®‰è£…\")"
        ],
        "execution_count": None,
        "outputs": []
    })

    # Cell 4: æ£€æŸ¥ GPU
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {"id": "gpu"},
        "source": [
            "# 3. æ£€æŸ¥ GPU å¯ç”¨æ€§\n",
            "import torch\n",
            "\n",
            "if torch.cuda.is_available():\n",
            "    print(f\"âœ… GPU å¯ç”¨: {torch.cuda.get_device_name(0)}\")\n",
            "    print(f\"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
            "else:\n",
            "    print(\"âš ï¸ GPU ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU è®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰\")\n",
            "    print(\"   å»ºè®®: Runtime > Change runtime type > GPU\")"
        ],
        "execution_count": None,
        "outputs": []
    })

    # Cell 5: æ£€æŸ¥æ•°æ®
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {"id": "data"},
        "source": [
            "# 4. æ£€æŸ¥æ•°æ®é›†\n",
            "import pandas as pd\n",
            "from pathlib import Path\n",
            "\n",
            "data_files = list(Path('data').rglob('*.xlsx'))\n",
            "print(f\"æ‰¾åˆ° {len(data_files)} ä¸ªæ•°æ®æ–‡ä»¶:\")\n",
            "for f in data_files:\n",
            "    print(f\"  - {f}\")\n",
            "\n",
            "if data_files:\n",
            "    df = pd.read_excel(data_files[0])\n",
            "    print(f\"\\næ•°æ®é›†å¤§å°: {len(df)} æ¡\")\n",
            "    print(f\"\\næ”»å‡»ç±»å‹åˆ†å¸ƒ:\")\n",
            "    print(df.iloc[:, -1].value_counts())\n",
            "else:\n",
            "    print(\"\\nâš ï¸ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })

    # Cell 6: æ•°æ®é¢„å¤„ç†
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {"id": "preprocess"},
        "source": [
            "# 5. æ•°æ®é¢„å¤„ç†\n",
            "print(\"ğŸ”„ å¼€å§‹æ•°æ®é¢„å¤„ç†...\")\n",
            "\n",
            "import glob\n",
            "excel_files = glob.glob('data/**/*.xlsx', recursive=True)\n",
            "\n",
            "if excel_files:\n",
            "    data_file = excel_files[0]\n",
            "    print(f\"ä½¿ç”¨æ•°æ®æ–‡ä»¶: {data_file}\")\n",
            "    !python scripts/ingest.py \"{data_file}\"\n",
            "    print(\"\\nâœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼\")\n",
            "\n",
            "    parquet_files = glob.glob('data/staging/*.parquet')\n",
            "    print(f\"\\nç”Ÿæˆçš„ parquet æ–‡ä»¶: {parquet_files}\")\n",
            "else:\n",
            "    print(\"âŒ æœªæ‰¾åˆ° Excel æ•°æ®æ–‡ä»¶ï¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })

    # Cell 7: æ•°æ®å¢å¼º
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {"id": "augment"},
        "source": [
            "# 6. æ•°æ®å¢å¼º\n",
            "print(\"=\"*60)\n",
            "print(\"ğŸš€ æ•°æ®å¢å¼ºå¼€å§‹\")\n",
            "print(\"=\"*60)\n",
            "print(\"\\nç­–ç•¥:\")\n",
            "print(\"  - SQL æ³¨å…¥: å…³é”®è¯æ›¿æ¢ã€æ³¨é‡Šå˜æ¢ã€ç©ºæ ¼ç¼–ç \")\n",
            "print(\"  - XSS æ”»å‡»: æ ‡ç­¾å¤§å°å†™ã€äº‹ä»¶å¤„ç†å™¨ã€ç¼–ç å˜æ¢\")\n",
            "print(\"  - å‘½ä»¤æ³¨å…¥: åˆ†éš”ç¬¦å˜æ¢ã€å‘½ä»¤ç»„åˆ\")\n",
            "print(\"  - URL è·¯å¾„: å¤§å°å†™ã€ç¼–ç ã€è·¯å¾„åˆ†éš”ç¬¦\")\n",
            "print(\"\\nç›®æ ‡: 11,000 â†’ 30,000+ æ¡ (2.7x)\\n\")\n",
            "\n",
            "!python scripts/augment_data.py --target-size 30000 --ratio 2.5\n",
            "\n",
            "print(\"\\n\" + \"=\"*60)\n",
            "print(\"âœ… æ•°æ®å¢å¼ºå®Œæˆï¼\")\n",
            "print(\"=\"*60)\n",
            "\n",
            "# æŸ¥çœ‹å¢å¼ºåçš„æ•°æ®\n",
            "import pandas as pd\n",
            "import glob\n",
            "\n",
            "augmented_files = glob.glob('data/staging/*augmented*.parquet')\n",
            "if augmented_files:\n",
            "    df_aug = pd.read_parquet(augmented_files[0])\n",
            "    print(f\"\\nğŸ“Š å¢å¼ºåç»Ÿè®¡:\")\n",
            "    print(f\"  æ€»æ•°æ®é‡: {len(df_aug)} æ¡\")\n",
            "    print(f\"  å¢å¼ºå€æ•°: {len(df_aug) / 11000:.2f}x\")\n",
            "    print(f\"\\nç±»åˆ«åˆ†å¸ƒ:\")\n",
            "    print(df_aug['attack_type'].value_counts())"
        ],
        "execution_count": None,
        "outputs": []
    })

    # Cell 8: è®­ç»ƒ V4 æ¨¡å‹
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {"id": "train"},
        "source": [
            "# 7. è®­ç»ƒ V4 æ¨¡å‹ï¼ˆSMOTE + ä¼˜åŒ–è¶…å‚æ•°ï¼‰\n",
            "print(\"=\"*60)\n",
            "print(\"ğŸš€ V4 æ¨¡å‹è®­ç»ƒå¼€å§‹ï¼ˆSOTA ä¼˜åŒ–ï¼‰\")\n",
            "print(\"=\"*60)\n",
            "print(\"\\né…ç½®:\")\n",
            "print(\"  - æ¨¡å‹: XGBoost + CatBoost + LightGBM\")\n",
            "print(\"  - é›†æˆæ–¹å¼: Stacking (ä¼˜åŒ– meta-learner)\")\n",
            "print(\"  - äº¤å‰éªŒè¯: 10 æŠ˜\")\n",
            "print(\"  - â­ SMOTE è¿‡é‡‡æ ·: æ˜¯ï¼ˆè§£å†³ç±»åˆ«ä¸å¹³è¡¡ï¼‰\")\n",
            "print(\"  - â­ XGBoost ä¼˜åŒ–: 500 æ ‘ + æ·±åº¦ 12\")\n",
            "print(\"  - é¢„è®¡æ—¶é—´: 30-40 åˆ†é’Ÿ\\n\")\n",
            "\n",
            "!python scripts/train_v4.py --version v4.0.0 --cv-splits 10\n",
            "\n",
            "print(\"\\n\" + \"=\"*60)\n",
            "print(\"âœ… V4 è®­ç»ƒå®Œæˆï¼\")\n",
            "print(\"=\"*60)"
        ],
        "execution_count": None,
        "outputs": []
    })

    # Cell 9: æŸ¥çœ‹ç»“æœ
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {"id": "results"},
        "source": [
            "# 8. æŸ¥çœ‹ V4 è®­ç»ƒç»“æœ\n",
            "import json\n",
            "from pathlib import Path\n",
            "\n",
            "manifest_path = Path('models/v4.0.0/manifest.json')\n",
            "\n",
            "if manifest_path.exists():\n",
            "    with open(manifest_path, 'r', encoding='utf-8') as f:\n",
            "        manifest = json.load(f)\n",
            "\n",
            "    print(\"=\"*70)\n",
            "    print(\"ğŸ“Š V4 è®­ç»ƒç»“æœï¼ˆSOTA ä¼˜åŒ–ï¼‰\")\n",
            "    print(\"=\"*70)\n",
            "    print(f\"\\nç‰ˆæœ¬: {manifest['version']}\")\n",
            "    print(f\"è®­ç»ƒæ—¶é—´: {manifest['trained_at']}\")\n",
            "    print(f\"æ•°æ®é‡: {manifest['data_rows']} æ¡\")\n",
            "    print(f\"ç‰¹å¾æ•°: {len(manifest['feature_list'])} ä¸ª\")\n",
            "    print(f\"ç±»åˆ«æ•°: {len(manifest['classes'])} ç±»\")\n",
            "\n",
            "    config = manifest.get('training_config', {})\n",
            "    print(f\"\\nè®­ç»ƒé…ç½®:\")\n",
            "    print(f\"  - äº¤å‰éªŒè¯: {config.get('n_cv_splits', 'N/A')} æŠ˜\")\n",
            "    print(f\"  - é›†æˆæ–¹å¼: {config.get('use_stacking', False) and 'Stacking' or 'Voting'}\")\n",
            "    print(f\"  - SMOTE è¿‡é‡‡æ ·: {config.get('use_smote', False) and 'æ˜¯' or 'å¦'}\")\n",
            "\n",
            "    print(\"\\n\" + \"=\"*70)\n",
            "    print(\"ğŸ¯ æ¨¡å‹æ€§èƒ½\")\n",
            "    print(\"=\"*70)\n",
            "\n",
            "    metrics = manifest['metrics']\n",
            "\n",
            "    # å•æ¨¡å‹æ€§èƒ½\n",
            "    for model_name in ['xgboost', 'catboost', 'lightgbm']:\n",
            "        if model_name in metrics:\n",
            "            m = metrics[model_name]\n",
            "            print(f\"\\n{model_name.upper()}:\")\n",
            "            print(f\"  æµ‹è¯•å‡†ç¡®ç‡: {m['test_accuracy']:.4f} ({m['test_accuracy']*100:.2f}%)\")\n",
            "            print(f\"  æµ‹è¯• F1: {m['test_f1']:.4f}\")\n",
            "            if m.get('cv_accuracy'):\n",
            "                print(f\"  CV å‡†ç¡®ç‡: {m['cv_accuracy']:.4f} (Â±{m.get('cv_std', 0):.4f})\")\n",
            "\n",
            "    # é›†æˆæ¨¡å‹æ€§èƒ½\n",
            "    if 'ensemble' in metrics:\n",
            "        e = metrics['ensemble']\n",
            "        print(f\"\\n{'='*70}\")\n",
            "        print(f\"ğŸ† V4 é›†æˆæ¨¡å‹ï¼ˆæœ€ç»ˆæ¨¡å‹ï¼‰\")\n",
            "        print(f\"{'='*70}\")\n",
            "        print(f\"  å‡†ç¡®ç‡: {e['test_accuracy']:.4f} ({e['test_accuracy']*100:.2f}%)\")\n",
            "        print(f\"  F1 åˆ†æ•°: {e['test_f1']:.4f}\")\n",
            "        print(f\"  é›†æˆæ–¹å¼: {e.get('ensemble_type', 'N/A')}\")\n",
            "\n",
            "        # ä¸ V3 å¯¹æ¯”\n",
            "        v3_acc = 0.9836  # V3 çš„å‡†ç¡®ç‡\n",
            "        improvement = (e['test_accuracy'] - v3_acc) * 100\n",
            "        print(f\"\\n  ğŸ“ˆ ç›¸æ¯” V3 æå‡: {improvement:+.2f}%\")\n",
            "\n",
            "        if e['test_accuracy'] >= 0.995:\n",
            "            print(f\"\\n  ğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼è¾¾åˆ° 99.5% ç›®æ ‡ï¼\")\n",
            "        elif e['test_accuracy'] >= 0.99:\n",
            "            print(f\"\\n  ğŸ‰ æ­å–œï¼è¾¾åˆ° 99% ç›®æ ‡ï¼\")\n",
            "        elif e['test_accuracy'] >= 0.985:\n",
            "            print(f\"\\n  âœ¨ éå¸¸æ¥è¿‘ 99%ï¼Œè¡¨ç°ä¼˜ç§€ï¼\")\n",
            "\n",
            "    print(\"\\n\" + \"=\"*70)\n",
            "\n",
            "    # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š\n",
            "    report_path = Path('models/v4.0.0/classification_report.txt')\n",
            "    if report_path.exists():\n",
            "        print(\"\\nğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:\")\n",
            "        print(\"=\"*70)\n",
            "        with open(report_path, 'r', encoding='utf-8') as f:\n",
            "            print(f.read())\n",
            "else:\n",
            "    print(\"âŒ æœªæ‰¾åˆ° V4 è®­ç»ƒç»“æœæ–‡ä»¶ï¼\")\n",
            "    print(\"è¯·å…ˆè¿è¡Œè®­ç»ƒå•å…ƒæ ¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })

    # Cell 10: ä¸‹è½½æ¨¡å‹
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {"id": "download"},
        "source": [
            "# 9. æ‰“åŒ…å¹¶ä¸‹è½½æ¨¡å‹\n",
            "import shutil\n",
            "from pathlib import Path\n",
            "\n",
            "model_dir = Path('models/v4.0.0')\n",
            "if model_dir.exists():\n",
            "    print(\"ğŸ“¦ æ‰“åŒ…æ¨¡å‹æ–‡ä»¶...\")\n",
            "    shutil.make_archive('models_v4.0.0', 'zip', 'models', 'v4.0.0')\n",
            "    print(\"âœ… æ‰“åŒ…å®Œæˆ: models_v4.0.0.zip\")\n",
            "    \n",
            "    # åœ¨ Colab ä¸­ä¸‹è½½\n",
            "    from google.colab import files\n",
            "    files.download('models_v4.0.0.zip')\n",
            "    print(\"\\nâœ… ä¸‹è½½å·²å¼€å§‹ï¼\")\n",
            "else:\n",
            "    print(\"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨ï¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })

    return notebook


def main():
    """ä¸»å‡½æ•°"""
    notebook = generate_v4_notebook()
    
    output_path = Path(__file__).parent.parent / "jupyter" / "colab_train_v4.ipynb"
    output_path.parent.mkdir(exist_ok=True)
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(notebook, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… V4 Notebook å·²ç”Ÿæˆ: {output_path}")
    print(f"ğŸ“ å¯ä»¥ä¸Šä¼ åˆ° Google Colab è¿›è¡Œè®­ç»ƒ")


if __name__ == "__main__":
    main()
