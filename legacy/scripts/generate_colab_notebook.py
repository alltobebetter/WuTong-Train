#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""ç”Ÿæˆ Colab è®­ç»ƒ Notebook"""

import json
from pathlib import Path


def create_notebook():
    """åˆ›å»º Jupyter Notebook ç»“æ„"""
    
    notebook = {
        "nbformat": 4,
        "nbformat_minor": 0,
        "metadata": {
            "colab": {
                "provenance": [],
                "gpuType": "T4"
            },
            "kernelspec": {
                "name": "python3",
                "display_name": "Python 3"
            },
            "language_info": {
                "name": "python"
            },
            "accelerator": "GPU"
        },
        "cells": []
    }
    
    # Cell 1: æ ‡é¢˜å’Œè¯´æ˜
    notebook["cells"].append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "# æ¢§æ¡æ¯ AI å®‰å…¨å‘Šè­¦æ™ºèƒ½ç ”åˆ¤ç³»ç»Ÿ - Colab è®­ç»ƒ\n",
            "\n",
            "## ğŸ“‹ è®­ç»ƒæµç¨‹\n",
            "\n",
            "1. âœ… å…‹éš† GitHub ä»“åº“\n",
            "2. âœ… å®‰è£…ä¾èµ–\n",
            "3. âœ… æ£€æŸ¥æ•°æ®\n",
            "4. âœ… æ•°æ®é¢„å¤„ç†\n",
            "5. âœ… è®­ç»ƒ V2 æ¨¡å‹ï¼ˆXGBoost + CatBoost + LightGBMï¼‰\n",
            "6. âœ… æŸ¥çœ‹è®­ç»ƒç»“æœ\n",
            "7. âœ… ä¸‹è½½æ¨¡å‹æ–‡ä»¶\n",
            "\n",
            "## âš™ï¸ è¿è¡Œå‰å‡†å¤‡\n",
            "\n",
            "1. ç¡®ä¿è¿è¡Œæ—¶ç±»å‹è®¾ç½®ä¸º **GPU**ï¼ˆRuntime > Change runtime type > GPUï¼‰\n",
            "2. æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªå•å…ƒæ ¼\n",
            "3. è®­ç»ƒæ—¶é—´çº¦ 10-15 åˆ†é’Ÿ\n",
            "\n",
            "---"
        ]
    })
    
    # Cell 2: å…‹éš†ä»“åº“
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 1. å…‹éš† GitHub ä»“åº“\n",
            "!git clone https://github.com/alltobebetter/WuTong.git\n",
            "%cd WuTong\n",
            "\n",
            "# æŸ¥çœ‹é¡¹ç›®ç»“æ„\n",
            "!ls -la"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 3: å®‰è£…ä¾èµ–
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 2. å®‰è£…ä¾èµ–\n",
            "print(\"ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...\")\n",
            "!pip install -q -r requirements-colab.txt\n",
            "\n",
            "print(\"\\nâœ… ä¾èµ–å®‰è£…å®Œæˆï¼\")\n",
            "\n",
            "# éªŒè¯å…³é”®åŒ…\n",
            "import xgboost as xgb\n",
            "import catboost as cb\n",
            "import lightgbm as lgb\n",
            "import pandas as pd\n",
            "\n",
            "print(f\"XGBoost ç‰ˆæœ¬: {xgb.__version__}\")\n",
            "print(f\"CatBoost ç‰ˆæœ¬: {cb.__version__}\")\n",
            "print(f\"LightGBM ç‰ˆæœ¬: {lgb.__version__}\")\n",
            "print(f\"Pandas ç‰ˆæœ¬: {pd.__version__}\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 4: æ£€æŸ¥ GPU
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 3. æ£€æŸ¥ GPU å¯ç”¨æ€§\n",
            "import torch\n",
            "\n",
            "if torch.cuda.is_available():\n",
            "    print(f\"âœ… GPU å¯ç”¨: {torch.cuda.get_device_name(0)}\")\n",
            "    print(f\"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
            "else:\n",
            "    print(\"âš ï¸ GPU ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU è®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰\")\n",
            "    print(\"   å»ºè®®: Runtime > Change runtime type > GPU\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 5: æ£€æŸ¥æ•°æ®
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 4. æ£€æŸ¥æ•°æ®é›†\n",
            "import pandas as pd\n",
            "from pathlib import Path\n",
            "\n",
            "# æŸ¥æ‰¾æ•°æ®æ–‡ä»¶\n",
            "data_files = list(Path('data').rglob('*.xlsx'))\n",
            "print(f\"æ‰¾åˆ° {len(data_files)} ä¸ªæ•°æ®æ–‡ä»¶:\")\n",
            "for f in data_files:\n",
            "    print(f\"  - {f}\")\n",
            "\n",
            "if data_files:\n",
            "    # è¯»å–ç¬¬ä¸€ä¸ªæ•°æ®æ–‡ä»¶\n",
            "    df = pd.read_excel(data_files[0])\n",
            "    print(f\"\\næ•°æ®é›†å¤§å°: {len(df)} æ¡\")\n",
            "    print(f\"\\nåˆ—å: {df.columns.tolist()}\")\n",
            "    print(f\"\\næ”»å‡»ç±»å‹åˆ†å¸ƒ:\")\n",
            "    print(df.iloc[:, -1].value_counts())\n",
            "else:\n",
            "    print(\"\\nâš ï¸ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼\")\n",
            "    print(\"è¯·ç¡®ä¿ data/ ç›®å½•ä¸‹æœ‰æ•°æ®æ–‡ä»¶\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 6: æ•°æ®é¢„å¤„ç†
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 5. æ•°æ®é¢„å¤„ç†\n",
            "print(\"ğŸ”„ å¼€å§‹æ•°æ®é¢„å¤„ç†...\")\n",
            "\n",
            "# æŸ¥æ‰¾ Excel æ–‡ä»¶\n",
            "import glob\n",
            "excel_files = glob.glob('data/**/*.xlsx', recursive=True)\n",
            "\n",
            "if excel_files:\n",
            "    data_file = excel_files[0]\n",
            "    print(f\"ä½¿ç”¨æ•°æ®æ–‡ä»¶: {data_file}\")\n",
            "    \n",
            "    # è¿è¡Œé¢„å¤„ç†\n",
            "    !python scripts/ingest.py \"{data_file}\"\n",
            "    \n",
            "    print(\"\\nâœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼\")\n",
            "    \n",
            "    # æ£€æŸ¥ç”Ÿæˆçš„ parquet æ–‡ä»¶\n",
            "    parquet_files = glob.glob('data/staging/*.parquet')\n",
            "    print(f\"\\nç”Ÿæˆçš„ parquet æ–‡ä»¶: {parquet_files}\")\n",
            "else:\n",
            "    print(\"âŒ æœªæ‰¾åˆ° Excel æ•°æ®æ–‡ä»¶ï¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 7: è®­ç»ƒæ¨¡å‹
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 6. è®­ç»ƒ V2 æ¨¡å‹ï¼ˆå®Œæ•´è®­ç»ƒï¼Œå¸¦äº¤å‰éªŒè¯ï¼‰\n",
            "print(\"ğŸš€ å¼€å§‹è®­ç»ƒ V2 æ¨¡å‹...\")\n",
            "print(\"æ¨¡å‹: XGBoost + CatBoost + LightGBM\")\n",
            "print(\"äº¤å‰éªŒè¯: 5 æŠ˜\")\n",
            "print(\"é¢„è®¡æ—¶é—´: 10-15 åˆ†é’Ÿ\\n\")\n",
            "\n",
            "!python scripts/train_v2.py --version v2.0.0\n",
            "\n",
            "print(\"\\nâœ… è®­ç»ƒå®Œæˆï¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 8: å¿«é€Ÿè®­ç»ƒï¼ˆå¯é€‰ï¼‰
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 6-alternative. å¿«é€Ÿè®­ç»ƒï¼ˆä¸å¸¦äº¤å‰éªŒè¯ï¼Œçº¦ 5 åˆ†é’Ÿï¼‰\n",
            "# å¦‚æœæƒ³å¿«é€Ÿæµ‹è¯•ï¼Œå¯ä»¥è¿è¡Œè¿™ä¸ªå•å…ƒæ ¼ä»£æ›¿ä¸Šé¢çš„å•å…ƒæ ¼\n",
            "\n",
            "# print(\"âš¡ å¿«é€Ÿè®­ç»ƒæ¨¡å¼ï¼ˆä¸å¸¦äº¤å‰éªŒè¯ï¼‰...\")\n",
            "# !python scripts/train_v2.py --version v2.0.0-fast --no-cv\n",
            "# print(\"\\nâœ… å¿«é€Ÿè®­ç»ƒå®Œæˆï¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 9: æŸ¥çœ‹è®­ç»ƒç»“æœ
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 7. æŸ¥çœ‹è®­ç»ƒç»“æœ\n",
            "import json\n",
            "from pathlib import Path\n",
            "\n",
            "manifest_path = Path('models/v2.0.0/manifest.json')\n",
            "\n",
            "if manifest_path.exists():\n",
            "    with open(manifest_path, 'r', encoding='utf-8') as f:\n",
            "        manifest = json.load(f)\n",
            "    \n",
            "    print(\"=\" * 60)\n",
            "    print(\"ğŸ“Š è®­ç»ƒç»“æœ\")\n",
            "    print(\"=\" * 60)\n",
            "    print(f\"\\nç‰ˆæœ¬: {manifest['version']}\")\n",
            "    print(f\"è®­ç»ƒæ—¶é—´: {manifest['trained_at']}\")\n",
            "    print(f\"æ•°æ®é‡: {manifest['data_rows']} æ¡\")\n",
            "    print(f\"ç‰¹å¾æ•°: {len(manifest['feature_list'])} ä¸ª\")\n",
            "    print(f\"ç±»åˆ«æ•°: {len(manifest['classes'])} ç±»\")\n",
            "    \n",
            "    print(\"\\n\" + \"=\" * 60)\n",
            "    print(\"ğŸ¯ æ¨¡å‹æ€§èƒ½\")\n",
            "    print(\"=\" * 60)\n",
            "    \n",
            "    metrics = manifest['metrics']\n",
            "    \n",
            "    # å•æ¨¡å‹æ€§èƒ½\n",
            "    for model_name in ['xgboost', 'catboost', 'lightgbm']:\n",
            "        if model_name in metrics:\n",
            "            m = metrics[model_name]\n",
            "            print(f\"\\n{model_name.upper()}:\")\n",
            "            print(f\"  æµ‹è¯•å‡†ç¡®ç‡: {m['test_accuracy']:.4f}\")\n",
            "            print(f\"  æµ‹è¯• F1: {m['test_f1']:.4f}\")\n",
            "            if m.get('cv_accuracy'):\n",
            "                print(f\"  äº¤å‰éªŒè¯å‡†ç¡®ç‡: {m['cv_accuracy']:.4f}\")\n",
            "    \n",
            "    # é›†æˆæ¨¡å‹æ€§èƒ½\n",
            "    if 'ensemble' in metrics:\n",
            "        e = metrics['ensemble']\n",
            "        print(f\"\\n{'='*60}\")\n",
            "        print(f\"ğŸ† é›†æˆæ¨¡å‹ï¼ˆæœ€ç»ˆæ¨¡å‹ï¼‰\")\n",
            "        print(f\"{'='*60}\")\n",
            "        print(f\"  å‡†ç¡®ç‡: {e['test_accuracy']:.4f} ({e['test_accuracy']*100:.2f}%)\")\n",
            "        print(f\"  F1 åˆ†æ•°: {e['test_f1']:.4f}\")\n",
            "    \n",
            "    print(\"\\n\" + \"=\" * 60)\n",
            "    \n",
            "    # è¯»å–è¯¦ç»†åˆ†ç±»æŠ¥å‘Š\n",
            f"    report_path = Path('models/{train_version}/classification_report.txt')\n",
            "    if report_path.exists():\n",
            "        print(\"\\nğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:\")\n",
            "        print(\"=\" * 60)\n",
            "        with open(report_path, 'r', encoding='utf-8') as f:\n",
            "            print(f.read())\n",
            "else:\n",
            "    print(\"âŒ æœªæ‰¾åˆ°è®­ç»ƒç»“æœæ–‡ä»¶ï¼\")\n",
            "    print(\"è¯·å…ˆè¿è¡Œè®­ç»ƒå•å…ƒæ ¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 10: å¯¹æ¯”æ¨¡å‹
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 8. å¯¹æ¯”ä¸åŒç‰ˆæœ¬æ¨¡å‹ï¼ˆå¦‚æœæœ‰ V1 æ¨¡å‹ï¼‰\n",
            "!python scripts/compare_models.py"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 11: æ‰“åŒ…ä¸‹è½½
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 9. æ‰“åŒ…æ¨¡å‹æ–‡ä»¶å‡†å¤‡ä¸‹è½½\n",
            "print(\"ğŸ“¦ æ‰“åŒ…æ¨¡å‹æ–‡ä»¶...\")\n",
            "\n",
            "!zip -r models_v2.0.0.zip models/v2.0.0/\n",
            "\n",
            "print(\"\\nâœ… æ‰“åŒ…å®Œæˆï¼\")\n",
            "print(\"\\næ–‡ä»¶å¤§å°:\")\n",
            "!ls -lh models_v2.0.0.zip"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 12: ä¸‹è½½æ–‡ä»¶
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 10. ä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ°æœ¬åœ°\n",
            "from google.colab import files\n",
            "\n",
            "print(\"â¬‡ï¸ å¼€å§‹ä¸‹è½½æ¨¡å‹æ–‡ä»¶...\")\n",
            "print(\"ï¼ˆä¸‹è½½å®Œæˆåè§£å‹åˆ°æœ¬åœ°é¡¹ç›®çš„ models/ ç›®å½•ï¼‰\\n\")\n",
            "\n",
            "files.download('models_v2.0.0.zip')\n",
            "\n",
            "print(\"\\nâœ… ä¸‹è½½å®Œæˆï¼\")\n",
            "print(\"\\nğŸ“ åç»­æ­¥éª¤:\")\n",
            "print(\"1. è§£å‹ models_v2.0.0.zip\")\n",
            "print(\"2. å°† models/v2.0.0/ ç›®å½•å¤åˆ¶åˆ°æœ¬åœ°é¡¹ç›®\")\n",
            "print(\"3. è¿è¡Œæ¨ç†: python scripts/infer.py data/xxx.xlsx --model-version v2.0.0\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 13: æµ‹è¯•æ¨ç†ï¼ˆå¯é€‰ï¼‰
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 11. æµ‹è¯•æ¨ç†ï¼ˆå¯é€‰ï¼‰\n",
            "import glob\n",
            "\n",
            "excel_files = glob.glob('data/**/*.xlsx', recursive=True)\n",
            "if excel_files:\n",
            "    test_file = excel_files[0]\n",
            "    print(f\"ğŸ§ª æµ‹è¯•æ¨ç†: {test_file}\")\n",
            "    \n",
            "    !python scripts/infer.py \"{test_file}\" --model-version v2.0.0 --job-id colab_test\n",
            "    \n",
            "    print(\"\\nâœ… æ¨ç†å®Œæˆï¼\")\n",
            "    print(\"\\næŸ¥çœ‹ç»“æœ:\")\n",
            "    !ls -la data/outputs/colab_test/\n",
            "else:\n",
            "    print(\"âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 14: æ€»ç»“
    notebook["cells"].append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            "## âœ… è®­ç»ƒå®Œæˆï¼\n",
            "\n",
            "### ğŸ“Š å…³é”®æŒ‡æ ‡\n",
            "\n",
            "- **æ¨¡å‹æ¶æ„**: XGBoost + CatBoost + LightGBM ä¸‰æ¨¡å‹é›†æˆ\n",
            "- **é¢„æœŸå‡†ç¡®ç‡**: 98.5-99.5%\n",
            "- **è®­ç»ƒæ–¹å¼**: 5 æŠ˜äº¤å‰éªŒè¯\n",
            "- **æ•°æ®é‡**: 11,000 æ¡å‘Šè­¦æ•°æ®\n",
            "- **æ”»å‡»ç±»å‹**: 9 ç±»ï¼ˆ8 ç§æ”»å‡» + æ­£å¸¸è®¿é—®ï¼‰\n",
            "\n",
            "### ğŸ“¦ å·²ç”Ÿæˆæ–‡ä»¶\n",
            "\n",
            "```\n",
            "models/v2.0.0/\n",
            "â”œâ”€â”€ ensemble.pkl              # é›†æˆæ¨¡å‹ï¼ˆä¸»è¦ä½¿ç”¨ï¼‰\n",
            "â”œâ”€â”€ xgboost.pkl               # XGBoost å•æ¨¡å‹\n",
            "â”œâ”€â”€ catboost.pkl              # CatBoost å•æ¨¡å‹\n",
            "â”œâ”€â”€ lightgbm.pkl              # LightGBM å•æ¨¡å‹\n",
            "â”œâ”€â”€ label_encoder.pkl         # æ ‡ç­¾ç¼–ç å™¨\n",
            "â”œâ”€â”€ aggregator.pkl            # å‘Šè­¦èšåˆå™¨\n",
            "â”œâ”€â”€ manifest.json             # æ¨¡å‹å…ƒæ•°æ®\n",
            "â”œâ”€â”€ feature_list.json         # ç‰¹å¾åˆ—è¡¨\n",
            "â””â”€â”€ classification_report.txt # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š\n",
            "```\n",
            "\n",
            "### ğŸš€ ä¸‹ä¸€æ­¥\n",
            "\n",
            "1. âœ… ä¸‹è½½ `models_v2.0.0.zip` åˆ°æœ¬åœ°\n",
            "2. âœ… è§£å‹åˆ°é¡¹ç›®çš„ `models/` ç›®å½•\n",
            "3. âœ… åœ¨æœ¬åœ° CPU ä¸Šè¿è¡Œæ¨ç†ï¼ˆå®Œå…¨å…¼å®¹ï¼‰\n",
            "4. âœ… é›†æˆåˆ° API æœåŠ¡æˆ– Electron å‰ç«¯\n",
            "\n",
            "### â“ å¸¸è§é—®é¢˜\n",
            "\n",
            "**Q: Colab è®­ç»ƒçš„æ¨¡å‹èƒ½åœ¨æœ¬åœ° CPU è¿è¡Œå—ï¼Ÿ**  \n",
            "A: å®Œå…¨å¯ä»¥ï¼æ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨çš„æ˜¯ CPU æŒ‡ä»¤ï¼ŒGPU åªæ˜¯åŠ é€Ÿè®¡ç®—ã€‚ä¸‹è½½åå¯ä»¥ç›´æ¥åœ¨ä»»ä½• CPU ç¯å¢ƒè¿è¡Œã€‚\n",
            "\n",
            "**Q: å‡†ç¡®ç‡æ²¡è¾¾åˆ°é¢„æœŸæ€ä¹ˆåŠï¼Ÿ**  \n",
            "A: å¯ä»¥å°è¯•ï¼š\n",
            "- å¢åŠ äº¤å‰éªŒè¯æŠ˜æ•°ï¼š`--cv-splits 10`\n",
            "- è°ƒæ•´æ¨¡å‹è¶…å‚æ•°\n",
            "- è¡¥å……å…¬å¼€æ•°æ®é›†\n",
            "\n",
            "**Q: æ¨¡å‹æ–‡ä»¶å¤ªå¤§æ€ä¹ˆåŠï¼Ÿ**  \n",
            "A: åªä¿ç•™ `ensemble.pkl`ã€`label_encoder.pkl`ã€`aggregator.pkl` å’Œé…ç½®æ–‡ä»¶å³å¯ï¼Œå•æ¨¡å‹æ–‡ä»¶å¯ä»¥åˆ é™¤ã€‚\n",
            "\n",
            "---\n",
            "\n",
            "**é¡¹ç›®åœ°å€**: https://github.com/alltobebetter/WuTong\n"
        ]
    })
    
    return notebook


def main():
    """ç”Ÿæˆå¹¶ä¿å­˜ notebook"""
    notebook = create_notebook()
    
    output_path = Path(__file__).parent.parent / "colab_train.ipynb"
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(notebook, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Notebook å·²ç”Ÿæˆ: {output_path}")
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024:.2f} KB")
    print(f"\nä½¿ç”¨æ–¹æ³•:")
    print(f"1. ä¸Šä¼  colab_train.ipynb åˆ° Google Colab")
    print(f"2. è®¾ç½®è¿è¡Œæ—¶ä¸º GPU")
    print(f"3. æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰å•å…ƒæ ¼")


if __name__ == "__main__":
    main()
