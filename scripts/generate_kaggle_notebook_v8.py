#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""ç”Ÿæˆ Kaggle ä¸€é”®è®­ç»ƒ Notebookï¼ˆV8ï¼‰"""

import json
from pathlib import Path


def _md_cell(lines): return {"cell_type": "markdown", "metadata": {}, "source": lines}
def _code_cell(lines): return {"cell_type": "code", "metadata": {}, "source": lines, "execution_count": None, "outputs": []}


def generate_notebook() -> dict:
    nb = {
        "nbformat": 4, "nbformat_minor": 5,
        "metadata": {
            "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
            "language_info": {"name": "python"},
        },
        "cells": [],
    }

    nb["cells"].append(_md_cell([
        "# WuTong V8 Kaggle ä¸€é”®è®­ç»ƒ\n",
        "\n",
        "V8 æ ¸å¿ƒæ”¹è¿›ï¼ˆç›®æ ‡ 99.5%+ï¼‰ï¼š\n",
        "- é’ˆå¯¹æ€§åŒºåˆ†ç‰¹å¾ï¼šæ–‡ä»¶åŒ…å« vs ç›®å½•éå†ã€SQL vs XSS\n",
        "- ç‰¹å¾é‡è¦æ€§ç­›é€‰ï¼ˆå»å™ªå£°ï¼‰\n",
        "- Stacking passthroughï¼ˆmeta-learner çœ‹åŸå§‹ç‰¹å¾ï¼‰\n",
        "- å¤šç§å­é›†æˆï¼ˆ3 seeds Ã— 4 models = 12 models æ¦‚ç‡å¹³å‡ï¼‰\n",
        "- Optuna 50 trialsï¼ˆåŸºäº V7 æœ€ä¼˜å‚æ•° warm startï¼‰\n",
        "\n",
        "ç›´æ¥ **Run All**ï¼Œé¢„è®¡ 40-50 åˆ†é’Ÿã€‚\n",
    ]))

    nb["cells"].append(_code_cell([
        "# 1) å…‹éš†/æ›´æ–°ä»£ç \n",
        "from pathlib import Path\n",
        "import os\n",
        "repo_dir = Path('/kaggle/working/WuTong')\n",
        "if repo_dir.exists():\n",
        "    os.system(f'cd {repo_dir} && git pull')\n",
        "else:\n",
        "    os.system('git clone https://github.com/alltobebetter/WuTong-Train.git /kaggle/working/WuTong')\n",
        "%cd /kaggle/working/WuTong\n",
        "!git log --oneline -n 5\n",
    ]))

    nb["cells"].append(_code_cell([
        "# 2) å®‰è£…ä¾èµ–\n",
        "!pip -q install -r requirements.txt\n",
        "!pip -q install imbalanced-learn optuna\n",
        "import torch\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available(): print('GPU:', torch.cuda.get_device_name(0))\n",
    ]))

    nb["cells"].append(_code_cell([
        "# 3) å‡†å¤‡æ•°æ®\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "raw_dir = Path('data/raw')\n",
        "raw_dir.mkdir(parents=True, exist_ok=True)\n",
        "repo_data = list(Path('data_raw').glob('*.xlsx')) + list(Path('data_raw').glob('*.csv'))\n",
        "if repo_data:\n",
        "    print(f'ä»ä»“åº“ data_raw/ æ‰¾åˆ° {len(repo_data)} ä¸ªæ•°æ®æ–‡ä»¶')\n",
        "    for src in repo_data:\n",
        "        dst = raw_dir / src.name\n",
        "        if not dst.exists(): shutil.copy2(src, dst)\n",
        "else:\n",
        "    candidates = list(Path('/kaggle/input').rglob('*.xlsx')) + list(Path('/kaggle/input').rglob('*.csv'))\n",
        "    for src in candidates[:20]:\n",
        "        dst = raw_dir / src.name\n",
        "        if not dst.exists(): shutil.copy2(src, dst)\n",
        "print('\\ndata/raw files:')\n",
        "for p in sorted(raw_dir.glob('*')): print(f'  - {p.name} ({p.stat().st_size/1024:.0f} KB)')\n",
        "if not list(raw_dir.glob('*')): raise RuntimeError('æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼')\n",
    ]))

    nb["cells"].append(_code_cell([
        "# 4) é¢„å¤„ç† + å¢å¼º + å¤–éƒ¨æ•°æ®\n",
        "import glob, os\n",
        "source_files = glob.glob('data/raw/*.xlsx') + glob.glob('data/raw/*.csv')\n",
        "if not source_files: raise RuntimeError('data/raw æ²¡æœ‰å¯ç”¨æ•°æ®')\n",
        "src = source_files[0]\n",
        "print('Using:', src)\n",
        "ret = os.system(f'python -u scripts/ingest.py \"{src}\"')\n",
        "if ret != 0: raise RuntimeError('ingest å¤±è´¥')\n",
        "ret = os.system('python -u scripts/augment_data.py --target-size 30000 --ratio 2.5')\n",
        "if ret != 0: raise RuntimeError('augment å¤±è´¥')\n",
        "ret = os.system('python -u scripts/integrate_csic2010.py')\n",
        "if ret != 0: print('âš ï¸ å¤–éƒ¨æ•°æ®ä¸‹è½½å¤±è´¥')\n",
        "print('preprocess done')\n",
    ]))

    nb["cells"].append(_code_cell([
        "# 5) V8 è®­ç»ƒ\n",
        "import subprocess, sys\n",
        "print('='*80)\n",
        "print('ğŸš€ V8 è®­ç»ƒå¼€å§‹')\n",
        "print('='*80)\n",
        "print('\\næ ¸å¿ƒæ”¹è¿›ï¼ˆvs V7 99.35%ï¼‰:')\n",
        "print('  - é’ˆå¯¹æ€§åŒºåˆ†ç‰¹å¾ï¼ˆæ–‡ä»¶åŒ…å«/ç›®å½•éå†ã€SQL/XSSï¼‰')\n",
        "print('  - ç‰¹å¾é‡è¦æ€§ç­›é€‰')\n",
        "print('  - Stacking passthrough + å¤šç§å­é›†æˆ')\n",
        "print('  - Optuna 50 trials\\n')\n",
        "cmd = [sys.executable, '-u', 'scripts/train_v8.py',\n",
        "       '--version', 'v8.0.0-kaggle', '--cv-splits', '10', '--optuna-trials', '50']\n",
        "proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
        "for line in proc.stdout: print(line, end='')\n",
        "ret = proc.wait()\n",
        "if ret != 0: raise RuntimeError(f'è®­ç»ƒå¤±è´¥: {ret}')\n",
        "print('\\n' + '='*80)\n",
        "print('âœ… V8 è®­ç»ƒå®Œæˆï¼')\n",
        "print('='*80)\n",
    ]))

    nb["cells"].append(_code_cell([
        "# 6) æŸ¥çœ‹ç»“æœ\n",
        "from pathlib import Path\n",
        "import json\n",
        "manifest_path = Path('models/v8.0.0-kaggle/manifest.json')\n",
        "if manifest_path.exists():\n",
        "    with open(manifest_path, 'r', encoding='utf-8') as f:\n",
        "        manifest = json.load(f)\n",
        "    print('='*80)\n",
        "    print('ğŸ“Š V8 è®­ç»ƒç»“æœ')\n",
        "    print('='*80)\n",
        "    print(f\"\\nç‰ˆæœ¬: {manifest['version']}\")\n",
        "    print(f\"æ•°æ®é‡: {manifest['data_rows']} æ¡\")\n",
        "    print(f\"ç‰¹å¾æ•°: {len(manifest['feature_list'])} ä¸ª\")\n",
        "    print(f\"Optuna: {manifest['training_config'].get('use_optuna')}\")\n",
        "    print(f\"å¤šç§å­: {manifest['training_config'].get('use_multi_seed')}\")\n",
        "    print('\\n' + '='*80)\n",
        "    print('ğŸ¯ æ¨¡å‹æ€§èƒ½')\n",
        "    print('='*80)\n",
        "    metrics = manifest['metrics']\n",
        "    for name in ['xgboost', 'catboost', 'lightgbm', 'extratrees']:\n",
        "        if name not in metrics: continue\n",
        "        m = metrics[name]\n",
        "        cv_str = f\", CV: {m['cv_accuracy']:.4f}\" if m.get('cv_accuracy') else ''\n",
        "        print(f\"  {name}: Acc={m['test_accuracy']:.4f}, F1={m['test_f1']:.4f}{cv_str}\")\n",
        "    e = metrics['ensemble']\n",
        "    print(f\"\\nğŸ† é›†æˆæ¨¡å‹ï¼ˆ{e['ensemble_type']}ï¼‰\")\n",
        "    print(f\"  å‡†ç¡®ç‡: {e['test_accuracy']:.4f} ({e['test_accuracy']*100:.2f}%)\")\n",
        "    print(f\"  F1 åˆ†æ•°: {e['test_f1']:.4f}\")\n",
        "    v7_acc = 0.9935\n",
        "    delta = e['test_accuracy'] - v7_acc\n",
        "    print(f\"\\n  vs V7: {'+' if delta >= 0 else ''}{delta*100:.2f}%\")\n",
        "    if 'all_ensembles' in metrics:\n",
        "        print('\\n  æ‰€æœ‰é›†æˆæ–¹æ¡ˆ:')\n",
        "        for k, v in metrics['all_ensembles'].items():\n",
        "            print(f'    {k}: {v:.4f}')\n",
        "    if e['test_accuracy'] >= 0.995: print('\\n  ğŸ‰ğŸ‰ è¾¾åˆ° 99.5% ç›®æ ‡ï¼')\n",
        "    elif e['test_accuracy'] >= 0.99: print('\\n  ğŸ‰ è¾¾åˆ° 99% ç›®æ ‡ï¼')\n",
        "    print('\\n' + '='*80)\n",
        "else:\n",
        "    print('âŒ æœªæ‰¾åˆ°è®­ç»ƒç»“æœ')\n",
    ]))

    nb["cells"].append(_code_cell([
        "# 7) æ‰“åŒ…ä¸‹è½½\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "model_dir = Path('models/v8.0.0-kaggle')\n",
        "if model_dir.exists():\n",
        "    archive = shutil.make_archive('/kaggle/working/models_v8.0.0-kaggle', 'zip', 'models', 'v8.0.0-kaggle')\n",
        "    print(f'âœ… æ‰“åŒ…å®Œæˆ: {archive}')\n",
        "    print(f'æ–‡ä»¶å¤§å°: {Path(archive).stat().st_size/1024/1024:.2f} MB')\n",
        "else:\n",
        "    print('âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨')\n",
    ]))

    return nb


def main():
    notebook = generate_notebook()
    output = Path(__file__).resolve().parent.parent / "jupyter" / "kaggle_train_v8.ipynb"
    output.parent.mkdir(parents=True, exist_ok=True)
    with open(output, "w", encoding="utf-8") as f:
        json.dump(notebook, f, ensure_ascii=False, indent=2)
    print(f"Kaggle notebook generated: {output}")


if __name__ == "__main__":
    main()
