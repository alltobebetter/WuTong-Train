#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""ç”Ÿæˆ Colab è®­ç»ƒ Notebook V3 - å†²å‡» 99%"""

import json
from pathlib import Path


def create_v3_notebook():
    """åˆ›å»º V3 Jupyter Notebook"""
    
    notebook = {
        "nbformat": 4,
        "nbformat_minor": 0,
        "metadata": {
            "colab": {
                "provenance": [],
                "gpuType": "T4"
            },
            "kernelspec": {
                "name": "python3",
                "display_name": "Python 3"
            },
            "language_info": {
                "name": "python"
            },
            "accelerator": "GPU"
        },
        "cells": []
    }
    
    # Cell 1: æ ‡é¢˜
    notebook["cells"].append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "# æ¢§æ¡æ¯ AI å®‰å…¨å‘Šè­¦æ™ºèƒ½ç ”åˆ¤ç³»ç»Ÿ - V3 å¢å¼ºç‰ˆï¼ˆå†²å‡» 99%ï¼‰\n",
            "\n",
            "## ğŸ¯ V3 æ”¹è¿›ç‚¹\n",
            "\n",
            "1. âœ¨ **æ•°æ®å¢å¼º**ï¼š11,000 â†’ 30,000+ æ¡ï¼ˆ2.7xï¼‰\n",
            "2. âœ¨ **Stacking é›†æˆ**ï¼šæ›¿ä»£ç®€å• Votingï¼Œå­¦ä¹ å„æ¨¡å‹ä¼˜åŠ¿\n",
            "3. âœ¨ **10 æŠ˜äº¤å‰éªŒè¯**ï¼šæ›´ç¨³å®šï¼Œå‡å°‘è¿‡æ‹Ÿåˆ\n",
            "4. âœ¨ **è¶…å‚æ•°ä¼˜åŒ–**ï¼šæ›´æ·±çš„æ ‘ã€æ›´å¤šè¿­ä»£\n",
            "\n",
            "## ğŸ“‹ è®­ç»ƒæµç¨‹\n",
            "\n",
            "1. âœ… å…‹éš† GitHub ä»“åº“\n",
            "2. âœ… å®‰è£…ä¾èµ–\n",
            "3. âœ… æ£€æŸ¥ GPU\n",
            "4. âœ… æ£€æŸ¥æ•°æ®\n",
            "5. âœ… æ•°æ®é¢„å¤„ç†\n",
            "6. âœ… **æ•°æ®å¢å¼ºï¼ˆV3 æ ¸å¿ƒï¼‰**\n",
            "7. âœ… è®­ç»ƒ V3 æ¨¡å‹\n",
            "8. âœ… æŸ¥çœ‹ç»“æœ\n",
            "9. âœ… ä¸‹è½½æ¨¡å‹\n",
            "\n",
            "## ğŸ¯ ç›®æ ‡\n",
            "\n",
            "- **å‡†ç¡®ç‡ç›®æ ‡**: 99%+\n",
            "- **è®­ç»ƒæ—¶é—´**: çº¦ 20-30 åˆ†é’Ÿ\n",
            "- **æ¨¡å‹ç‰ˆæœ¬**: v3.0.0\n",
            "\n",
            "## âš™ï¸ è¿è¡Œå‰å‡†å¤‡\n",
            "\n",
            "1. ç¡®ä¿è¿è¡Œæ—¶ç±»å‹è®¾ç½®ä¸º **GPU**ï¼ˆRuntime > Change runtime type > GPUï¼‰\n",
            "2. æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªå•å…ƒæ ¼\n",
            "\n",
            "---"
        ]
    })
    
    # Cell 2: å…‹éš†ä»“åº“
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 1. å…‹éš† GitHub ä»“åº“\n",
            "!git clone https://github.com/alltobebetter/WuTong.git\n",
            "%cd WuTong\n",
            "\n",
            "# æŸ¥çœ‹é¡¹ç›®ç»“æ„\n",
            "!ls -la"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 3: å®‰è£…ä¾èµ–
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 2. å®‰è£…ä¾èµ–\n",
            "print(\"ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...\")\n",
            "!pip install -q -r requirements.txt\n",
            "\n",
            "print(\"\\nâœ… ä¾èµ–å®‰è£…å®Œæˆï¼\")\n",
            "\n",
            "# éªŒè¯å…³é”®åŒ…\n",
            "import xgboost as xgb\n",
            "import catboost as cb\n",
            "import lightgbm as lgb\n",
            "import pandas as pd\n",
            "\n",
            "print(f\"XGBoost ç‰ˆæœ¬: {xgb.__version__}\")\n",
            "print(f\"CatBoost ç‰ˆæœ¬: {cb.__version__}\")\n",
            "print(f\"LightGBM ç‰ˆæœ¬: {lgb.__version__}\")\n",
            "print(f\"Pandas ç‰ˆæœ¬: {pd.__version__}\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 4: æ£€æŸ¥ GPU
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 3. æ£€æŸ¥ GPU å¯ç”¨æ€§\n",
            "import torch\n",
            "\n",
            "if torch.cuda.is_available():\n",
            "    print(f\"âœ… GPU å¯ç”¨: {torch.cuda.get_device_name(0)}\")\n",
            "    print(f\"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
            "else:\n",
            "    print(\"âš ï¸ GPU ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU è®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰\")\n",
            "    print(\"   å»ºè®®: Runtime > Change runtime type > GPU\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 5: æ£€æŸ¥æ•°æ®
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 4. æ£€æŸ¥æ•°æ®é›†\n",
            "import pandas as pd\n",
            "from pathlib import Path\n",
            "\n",
            "data_files = list(Path('data').rglob('*.xlsx'))\n",
            "print(f\"æ‰¾åˆ° {len(data_files)} ä¸ªæ•°æ®æ–‡ä»¶:\")\n",
            "for f in data_files:\n",
            "    print(f\"  - {f}\")\n",
            "\n",
            "if data_files:\n",
            "    df = pd.read_excel(data_files[0])\n",
            "    print(f\"\\næ•°æ®é›†å¤§å°: {len(df)} æ¡\")\n",
            "    print(f\"\\næ”»å‡»ç±»å‹åˆ†å¸ƒ:\")\n",
            "    print(df.iloc[:, -1].value_counts())\n",
            "else:\n",
            "    print(\"\\nâš ï¸ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 6: æ•°æ®é¢„å¤„ç†
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 5. æ•°æ®é¢„å¤„ç†\n",
            "print(\"ğŸ”„ å¼€å§‹æ•°æ®é¢„å¤„ç†...\")\n",
            "\n",
            "import glob\n",
            "excel_files = glob.glob('data/**/*.xlsx', recursive=True)\n",
            "\n",
            "if excel_files:\n",
            "    data_file = excel_files[0]\n",
            "    print(f\"ä½¿ç”¨æ•°æ®æ–‡ä»¶: {data_file}\")\n",
            "    !python scripts/ingest.py \"{data_file}\"\n",
            "    print(\"\\nâœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼\")\n",
            "    \n",
            "    parquet_files = glob.glob('data/staging/*.parquet')\n",
            "    print(f\"\\nç”Ÿæˆçš„ parquet æ–‡ä»¶: {parquet_files}\")\n",
            "else:\n",
            "    print(\"âŒ æœªæ‰¾åˆ° Excel æ•°æ®æ–‡ä»¶ï¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 7: æ•°æ®å¢å¼ºï¼ˆV3 æ ¸å¿ƒï¼‰
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 6. æ•°æ®å¢å¼ºï¼ˆV3 æ ¸å¿ƒ - å†²å‡» 99%ï¼‰\n",
            "print(\"=\"*60)\n",
            "print(\"ğŸš€ V3 æ•°æ®å¢å¼ºå¼€å§‹\")\n",
            "print(\"=\"*60)\n",
            "print(\"\\nç­–ç•¥:\")\n",
            "print(\"  - SQL æ³¨å…¥: å…³é”®è¯æ›¿æ¢ã€æ³¨é‡Šå˜æ¢ã€ç©ºæ ¼ç¼–ç \")\n",
            "print(\"  - XSS æ”»å‡»: æ ‡ç­¾å¤§å°å†™ã€äº‹ä»¶å¤„ç†å™¨ã€ç¼–ç å˜æ¢\")\n",
            "print(\"  - å‘½ä»¤æ³¨å…¥: åˆ†éš”ç¬¦å˜æ¢ã€å‘½ä»¤ç»„åˆ\")\n",
            "print(\"  - URL è·¯å¾„: å¤§å°å†™ã€ç¼–ç ã€è·¯å¾„åˆ†éš”ç¬¦\")\n",
            "print(\"\\nç›®æ ‡: 11,000 â†’ 30,000+ æ¡ (2.7x)\\n\")\n",
            "\n",
            "!python scripts/augment_data.py --target-size 30000 --ratio 2.5\n",
            "\n",
            "print(\"\\n\" + \"=\"*60)\n",
            "print(\"âœ… æ•°æ®å¢å¼ºå®Œæˆï¼\")\n",
            "print(\"=\"*60)\n",
            "\n",
            "# æŸ¥çœ‹å¢å¼ºåçš„æ•°æ®\n",
            "import pandas as pd\n",
            "import glob\n",
            "\n",
            "augmented_files = glob.glob('data/staging/*augmented*.parquet')\n",
            "if augmented_files:\n",
            "    df_aug = pd.read_parquet(augmented_files[0])\n",
            "    print(f\"\\nğŸ“Š å¢å¼ºåç»Ÿè®¡:\")\n",
            "    print(f\"  æ€»æ•°æ®é‡: {len(df_aug)} æ¡\")\n",
            "    print(f\"  å¢å¼ºå€æ•°: {len(df_aug) / 11000:.2f}x\")\n",
            "    print(f\"\\nç±»åˆ«åˆ†å¸ƒ:\")\n",
            "    print(df_aug['attack_type'].value_counts())"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 8: è®­ç»ƒ V3 æ¨¡å‹
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 7. è®­ç»ƒ V3 æ¨¡å‹ï¼ˆStacking + 10æŠ˜CVï¼‰\n",
            "print(\"=\"*60)\n",
            "print(\"ğŸš€ V3 æ¨¡å‹è®­ç»ƒå¼€å§‹\")\n",
            "print(\"=\"*60)\n",
            "print(\"\\né…ç½®:\")\n",
            "print(\"  - æ¨¡å‹: XGBoost + CatBoost + LightGBM\")\n",
            "print(\"  - é›†æˆæ–¹å¼: Stacking (Logistic Regression)\")\n",
            "print(\"  - äº¤å‰éªŒè¯: 10 æŠ˜\")\n",
            "print(\"  - è¶…å‚æ•°: ä¼˜åŒ–ç‰ˆï¼ˆæ›´æ·±çš„æ ‘ã€æ›´å¤šè¿­ä»£ï¼‰\")\n",
            "print(\"  - é¢„è®¡æ—¶é—´: 20-30 åˆ†é’Ÿ\\n\")\n",
            "\n",
            "!python scripts/train_v3.py --version v3.0.0 --cv-splits 10\n",
            "\n",
            "print(\"\\n\" + \"=\"*60)\n",
            "print(\"âœ… V3 è®­ç»ƒå®Œæˆï¼\")\n",
            "print(\"=\"*60)"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 9: å¿«é€Ÿè®­ç»ƒï¼ˆå¯é€‰ï¼‰
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 7-alternative. å¿«é€Ÿè®­ç»ƒï¼ˆä¸å¸¦äº¤å‰éªŒè¯ï¼Œçº¦ 10-15 åˆ†é’Ÿï¼‰\n",
            "# å¦‚æœæƒ³å¿«é€Ÿæµ‹è¯•ï¼Œå¯ä»¥è¿è¡Œè¿™ä¸ªå•å…ƒæ ¼ä»£æ›¿ä¸Šé¢çš„å•å…ƒæ ¼\n",
            "\n",
            "# print(\"âš¡ å¿«é€Ÿè®­ç»ƒæ¨¡å¼ï¼ˆä¸å¸¦äº¤å‰éªŒè¯ï¼‰...\")\n",
            "# !python scripts/train_v3.py --version v3.0.0-fast --no-cv\n",
            "# print(\"\\nâœ… å¿«é€Ÿè®­ç»ƒå®Œæˆï¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 10: æŸ¥çœ‹ç»“æœ
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 8. æŸ¥çœ‹ V3 è®­ç»ƒç»“æœ\n",
            "import json\n",
            "from pathlib import Path\n",
            "\n",
            "manifest_path = Path('models/v3.0.0/manifest.json')\n",
            "\n",
            "if manifest_path.exists():\n",
            "    with open(manifest_path, 'r', encoding='utf-8') as f:\n",
            "        manifest = json.load(f)\n",
            "    \n",
            "    print(\"=\"*70)\n",
            "    print(\"ğŸ“Š V3 è®­ç»ƒç»“æœ\")\n",
            "    print(\"=\"*70)\n",
            "    print(f\"\\nç‰ˆæœ¬: {manifest['version']}\")\n",
            "    print(f\"è®­ç»ƒæ—¶é—´: {manifest['trained_at']}\")\n",
            "    print(f\"æ•°æ®é‡: {manifest['data_rows']} æ¡\")\n",
            "    print(f\"ç‰¹å¾æ•°: {len(manifest['feature_list'])} ä¸ª\")\n",
            "    print(f\"ç±»åˆ«æ•°: {len(manifest['classes'])} ç±»\")\n",
            "    \n",
            "    config = manifest.get('training_config', {})\n",
            "    print(f\"\\nè®­ç»ƒé…ç½®:\")\n",
            "    print(f\"  - äº¤å‰éªŒè¯: {config.get('n_cv_splits', 'N/A')} æŠ˜\")\n",
            "    print(f\"  - é›†æˆæ–¹å¼: {config.get('use_stacking', False) and 'Stacking' or 'Voting'}\")\n",
            "    \n",
            "    print(\"\\n\" + \"=\"*70)\n",
            "    print(\"ğŸ¯ æ¨¡å‹æ€§èƒ½\")\n",
            "    print(\"=\"*70)\n",
            "    \n",
            "    metrics = manifest['metrics']\n",
            "    \n",
            "    # å•æ¨¡å‹æ€§èƒ½\n",
            "    for model_name in ['xgboost', 'catboost', 'lightgbm']:\n",
            "        if model_name in metrics:\n",
            "            m = metrics[model_name]\n",
            "            print(f\"\\n{model_name.upper()}:\")\n",
            "            print(f\"  æµ‹è¯•å‡†ç¡®ç‡: {m['test_accuracy']:.4f} ({m['test_accuracy']*100:.2f}%)\")\n",
            "            print(f\"  æµ‹è¯• F1: {m['test_f1']:.4f}\")\n",
            "            if m.get('cv_accuracy'):\n",
            "                print(f\"  CV å‡†ç¡®ç‡: {m['cv_accuracy']:.4f} (Â±{m.get('cv_std', 0):.4f})\")\n",
            "    \n",
            "    # é›†æˆæ¨¡å‹æ€§èƒ½\n",
            "    if 'ensemble' in metrics:\n",
            "        e = metrics['ensemble']\n",
            "        print(f\"\\n{'='*70}\")\n",
            "        print(f\"ğŸ† V3 é›†æˆæ¨¡å‹ï¼ˆæœ€ç»ˆæ¨¡å‹ï¼‰\")\n",
            "        print(f\"{'='*70}\")\n",
            "        print(f\"  å‡†ç¡®ç‡: {e['test_accuracy']:.4f} ({e['test_accuracy']*100:.2f}%)\")\n",
            "        print(f\"  F1 åˆ†æ•°: {e['test_f1']:.4f}\")\n",
            "        print(f\"  é›†æˆæ–¹å¼: {e.get('ensemble_type', 'N/A')}\")\n",
            "        \n",
            "        # ä¸ V2 å¯¹æ¯”\n",
            "        v2_acc = 0.9759  # V2 çš„å‡†ç¡®ç‡\n",
            "        improvement = (e['test_accuracy'] - v2_acc) * 100\n",
            "        print(f\"\\n  ğŸ“ˆ ç›¸æ¯” V2 æå‡: {improvement:+.2f}%\")\n",
            "        \n",
            "        if e['test_accuracy'] >= 0.99:\n",
            "            print(f\"\\n  ğŸ‰ æ­å–œï¼è¾¾åˆ° 99% ç›®æ ‡ï¼\")\n",
            "        elif e['test_accuracy'] >= 0.985:\n",
            "            print(f\"\\n  âœ¨ éå¸¸æ¥è¿‘ 99%ï¼Œè¡¨ç°ä¼˜ç§€ï¼\")\n",
            "    \n",
            "    print(\"\\n\" + \"=\"*70)\n",
            "    \n",
            "    # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š\n",
            "    report_path = Path('models/v3.0.0/classification_report.txt')\n",
            "    if report_path.exists():\n",
            "        print(\"\\nğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:\")\n",
            "        print(\"=\"*70)\n",
            "        with open(report_path, 'r', encoding='utf-8') as f:\n",
            "            print(f.read())\n",
            "else:\n",
            "    print(\"âŒ æœªæ‰¾åˆ° V3 è®­ç»ƒç»“æœæ–‡ä»¶ï¼\")\n",
            "    print(\"è¯·å…ˆè¿è¡Œè®­ç»ƒå•å…ƒæ ¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 11: å¯¹æ¯”æ‰€æœ‰ç‰ˆæœ¬
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 9. å¯¹æ¯” V2 vs V3\n",
            "print(\"ğŸ“Š æ¨¡å‹ç‰ˆæœ¬å¯¹æ¯”\\n\")\n",
            "!python scripts/compare_models.py"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 12: æ‰“åŒ…ä¸‹è½½
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 10. æ‰“åŒ… V3 æ¨¡å‹æ–‡ä»¶\n",
            "print(\"ğŸ“¦ æ‰“åŒ… V3 æ¨¡å‹æ–‡ä»¶...\")\n",
            "\n",
            "!zip -r models_v3.0.0.zip models/v3.0.0/\n",
            "\n",
            "print(\"\\nâœ… æ‰“åŒ…å®Œæˆï¼\")\n",
            "print(\"\\næ–‡ä»¶å¤§å°:\")\n",
            "!ls -lh models_v3.0.0.zip"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 13: ä¸‹è½½
    notebook["cells"].append({
        "cell_type": "code",
        "metadata": {},
        "source": [
            "# 11. ä¸‹è½½ V3 æ¨¡å‹åˆ°æœ¬åœ°\n",
            "from google.colab import files\n",
            "\n",
            "print(\"â¬‡ï¸ å¼€å§‹ä¸‹è½½ V3 æ¨¡å‹æ–‡ä»¶...\")\n",
            "print(\"ï¼ˆä¸‹è½½å®Œæˆåè§£å‹åˆ°æœ¬åœ°é¡¹ç›®çš„ models/ ç›®å½•ï¼‰\\n\")\n",
            "\n",
            "files.download('models_v3.0.0.zip')\n",
            "\n",
            "print(\"\\nâœ… ä¸‹è½½å®Œæˆï¼\")\n",
            "print(\"\\nğŸ“ åç»­æ­¥éª¤:\")\n",
            "print(\"1. è§£å‹ models_v3.0.0.zip\")\n",
            "print(\"2. å°† models/v3.0.0/ ç›®å½•å¤åˆ¶åˆ°æœ¬åœ°é¡¹ç›®\")\n",
            "print(\"3. è¿è¡Œæ¨ç†: python scripts/infer.py data/xxx.xlsx --model-version v3.0.0\")\n",
            "print(\"4. V3 æ¨¡å‹åœ¨ CPU ä¸Šè¿è¡Œå®Œå…¨æ²¡é—®é¢˜ï¼\")"
        ],
        "execution_count": None,
        "outputs": []
    })
    
    # Cell 14: æ€»ç»“
    notebook["cells"].append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            "## âœ… V3 è®­ç»ƒå®Œæˆï¼\n",
            "\n",
            "### ğŸ¯ V3 æ”¹è¿›æ€»ç»“\n",
            "\n",
            "| é¡¹ç›® | V2 | V3 | æå‡ |\n",
            "|------|----|----|------|\n",
            "| æ•°æ®é‡ | 11,000 | 30,000+ | 2.7x |\n",
            "| é›†æˆæ–¹å¼ | Voting | Stacking | âœ¨ |\n",
            "| äº¤å‰éªŒè¯ | 5 æŠ˜ | 10 æŠ˜ | âœ¨ |\n",
            "| è¶…å‚æ•° | åŸºç¡€ | ä¼˜åŒ– | âœ¨ |\n",
            "| é¢„æœŸå‡†ç¡®ç‡ | 97.5% | 99%+ | +1.5%+ |\n",
            "\n",
            "### ğŸ”‘ å…³é”®æ”¹è¿›\n",
            "\n",
            "1. **æ•°æ®å¢å¼º**ï¼ˆæœ€é‡è¦ï¼‰\n",
            "   - SQL æ³¨å…¥ï¼šå…³é”®è¯æ›¿æ¢ã€æ³¨é‡Šå˜æ¢\n",
            "   - XSS æ”»å‡»ï¼šæ ‡ç­¾å¤§å°å†™ã€äº‹ä»¶å¤„ç†å™¨\n",
            "   - å‘½ä»¤æ³¨å…¥ï¼šåˆ†éš”ç¬¦å˜æ¢\n",
            "   - URL è·¯å¾„ï¼šç¼–ç å˜æ¢ã€è·¯å¾„åˆ†éš”ç¬¦\n",
            "\n",
            "2. **Stacking é›†æˆ**\n",
            "   - å­¦ä¹ å„æ¨¡å‹çš„ä¼˜åŠ¿é¢†åŸŸ\n",
            "   - å¯¹éš¾åˆ†ç±»æ ·æœ¬ï¼ˆå¦‚ CSRFï¼‰æ•ˆæœæ›´å¥½\n",
            "\n",
            "3. **è¶…å‚æ•°ä¼˜åŒ–**\n",
            "   - æ ‘æ·±åº¦ï¼š8 â†’ 10\n",
            "   - è¿­ä»£æ¬¡æ•°ï¼š200 â†’ 300\n",
            "   - å­¦ä¹ ç‡ï¼š0.1 â†’ 0.05\n",
            "\n",
            "### ğŸ“¦ V3 æ¨¡å‹æ–‡ä»¶\n",
            "\n",
            "```\n",
            "models/v3.0.0/\n",
            "â”œâ”€â”€ ensemble.pkl              # Stacking é›†æˆæ¨¡å‹\n",
            "â”œâ”€â”€ xgboost.pkl               # XGBoost (300 æ£µæ ‘)\n",
            "â”œâ”€â”€ catboost.pkl              # CatBoost (300 è½®)\n",
            "â”œâ”€â”€ lightgbm.pkl              # LightGBM (300 æ£µæ ‘)\n",
            "â”œâ”€â”€ label_encoder.pkl         # æ ‡ç­¾ç¼–ç å™¨\n",
            "â”œâ”€â”€ aggregator.pkl            # å‘Šè­¦èšåˆå™¨\n",
            "â”œâ”€â”€ manifest.json             # æ¨¡å‹å…ƒæ•°æ®\n",
            "â”œâ”€â”€ feature_list.json         # ç‰¹å¾åˆ—è¡¨\n",
            "â””â”€â”€ classification_report.txt # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š\n",
            "```\n",
            "\n",
            "### ğŸ’¡ ä½¿ç”¨å»ºè®®\n",
            "\n",
            "1. **æœ¬åœ°æ¨ç†**ï¼šV3 æ¨¡å‹åœ¨ CPU ä¸Šè¿è¡Œå®Œå…¨æ²¡é—®é¢˜\n",
            "2. **API æœåŠ¡**ï¼šç›´æ¥æ›¿æ¢ V2 æ¨¡å‹å³å¯\n",
            "3. **æ¯”èµ›æäº¤**ï¼šåªæäº¤æ¨¡å‹æ–‡ä»¶ï¼Œä¸åŒ…å«åŸå§‹æ•°æ®\n",
            "\n",
            "### ğŸš€ å¦‚æœè¿˜æƒ³æå‡\n",
            "\n",
            "1. **è¡¥å……å…¬å¼€æ•°æ®é›†**ï¼šCSIC 2010ã€CICIDS2017\n",
            "2. **é’ˆå¯¹ CSRF ä¼˜åŒ–**ï¼šå•ç‹¬è®­ç»ƒäºŒåˆ†ç±»å™¨\n",
            "3. **ç‰¹å¾å·¥ç¨‹**ï¼šN-gramã€ç†µå€¼ã€ç¼–ç æ£€æµ‹\n",
            "\n",
            "---\n",
            "\n",
            "**é¡¹ç›®åœ°å€**: https://github.com/alltobebetter/WuTong\n",
            "\n",
            "**ç¥æ¯”èµ›é¡ºåˆ©ï¼å†²å‡» 99%ï¼** ğŸ‰\n"
        ]
    })
    
    return notebook


def main():
    """ç”Ÿæˆå¹¶ä¿å­˜ V3 notebook"""
    notebook = create_v3_notebook()
    
    output_path = Path(__file__).parent.parent / "colab_train_v3.ipynb"
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(notebook, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… V3 Notebook å·²ç”Ÿæˆ: {output_path}")
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024:.2f} KB")
    print(f"\nğŸ¯ V3 ç‰¹ç‚¹:")
    print(f"  - æ•°æ®å¢å¼º: 11k â†’ 30k+")
    print(f"  - Stacking é›†æˆ")
    print(f"  - 10 æŠ˜äº¤å‰éªŒè¯")
    print(f"  - ç›®æ ‡å‡†ç¡®ç‡: 99%+")
    print(f"\nä½¿ç”¨æ–¹æ³•:")
    print(f"1. ä¸Šä¼  colab_train_v3.ipynb åˆ° Google Colab")
    print(f"2. è®¾ç½®è¿è¡Œæ—¶ä¸º GPU")
    print(f"3. æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰å•å…ƒæ ¼")
    print(f"4. è®­ç»ƒæ—¶é—´çº¦ 20-30 åˆ†é’Ÿ")


if __name__ == "__main__":
    main()
